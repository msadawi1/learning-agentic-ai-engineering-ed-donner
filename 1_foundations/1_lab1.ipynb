{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Tell me a joke in one sentence only\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms? Because they make up everything! \n",
      "\n",
      "\n",
      "\n",
      "Hope you chuckled! 😄\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"anything\")\n",
    "response = ollama.chat.completions.create(model=\"gemma3:12b\", messages=messages)\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A perfectly symmetrical, toroidal (donut-shaped) solid object is constructed entirely of identical, infinitesimally small cubes. If the torus has an inner radius of *r* and an outer radius of *R*, and the total number of cubes used is minimized, what is a general expression for the number of cubes in terms of *r* and *R*?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=\"gemma3:12b\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let the inner radius of the torus be *r* and the outer radius be *R*. We want to minimize the number of cubes used to construct the torus, and the cubes are infinitesimally small.\n",
      "\n",
      "We can think of the torus as a surface of revolution. To minimize the number of cubes, we should use cubes with side length 1.  Let $n$ be the number of cubes along the cross-section (the circle) and $m$ be the number of cubes around the axis of the torus.\n",
      "\n",
      "The area of the cross-sectional region is the area between two circles with radii $r$ and $R$.  This area is $\\pi R^2 - \\pi r^2 = \\pi (R^2 - r^2)$. To minimize the number of cubes, we can approximate the area with the number of cubes required. We need $n$ cubes to form a circle of radius $R$. The area of the filled circle of radius $R$ is $\\pi R^2$, and the area of the circle of radius $r$ is $\\pi r^2$. Hence the number of cubes approximately equal to the area difference is $\\pi (R^2 - r^2)$.\n",
      "Since the number of cubes must be an integer, we can write $N \\approx \\pi (R^2 - r^2)$.\n",
      "\n",
      "We can consider the cross-section as a ring. The number of cubes around the circular loop is $m$. The number of cubes in the circular cross-section can be estimated as the area of the ring, which is $\\pi(R^2 - r^2)$.\n",
      "Let $C$ be the circumference of the central circle, which is $C = 2\\pi r$.\n",
      "The number of cubes in the cross-section is approximately the area of the toroidal surface, which is given by $A = (2\\pi r)(2\\pi R) = 4\\pi^2 rR$.\n",
      "To minimize the number of cubes, one must consider the smallest side length.\n",
      "However, we need to consider the fact that the torus can be viewed as a surface of revolution.\n",
      "We can visualize the torus as a collection of annuli.\n",
      "The torus is approximately $\\pi R^2 - \\pi r^2$ squared. This can be interpreted as the area of the cross section. The \"thickness\" of the donut is the side length of the small cubes, which we assume to be 1. So the number of cubes is the product of the area of the cross section and the area around it.\n",
      "\n",
      "The area of the cross-sectional ring is $\\pi(R^2 - r^2)$. The circumference of the hole is $2\\pi r$.\n",
      "So the total number of cubes is approximately $2\\pi r \\times \\pi (R^2 - r^2) = 2\\pi^2 r(R^2 - r^2)$.\n",
      "However, for the cubes to form a solid torus, we can express the volume as an integral, where the cross-sectional area varies.\n",
      "The number of cubes can be approximated as the surface area of the torus multiplied by the side length of the cube.\n",
      "Surface Area of Torus: $A = (2\\pi r)(2\\pi R) = 4\\pi^2 rR$.\n",
      "Let $s$ be the side length of the cube, which is minimized when $s$ is smallest.\n",
      "So the number of cubes is $4\\pi^2 rR$.\n",
      "Since we have infinitesimally small cubes, $s \\rightarrow 0$.\n",
      "The number of cubes is approximately $4\\pi^2 rR$.\n",
      "\n",
      "If the torus were assembled from unit cubes, then the number of cubes would be the volume of a cylinder with radii *r* and *R*, with length 1. The volume is $\\pi R^2 - \\pi r^2$, but this doesn't account for the fact that we have a torus.  Consider the torus as a surface of revolution. The area is $4 \\pi^2 r R$.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{4\\pi^2rR}$\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "response = ollama.chat.completions.create(model=\"gemma3:12b\", messages=messages)\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let the inner radius of the torus be *r* and the outer radius be *R*. We want to minimize the number of cubes used to construct the torus, and the cubes are infinitesimally small.\n",
       "\n",
       "We can think of the torus as a surface of revolution. To minimize the number of cubes, we should use cubes with side length 1.  Let $n$ be the number of cubes along the cross-section (the circle) and $m$ be the number of cubes around the axis of the torus.\n",
       "\n",
       "The area of the cross-sectional region is the area between two circles with radii $r$ and $R$.  This area is $\\pi R^2 - \\pi r^2 = \\pi (R^2 - r^2)$. To minimize the number of cubes, we can approximate the area with the number of cubes required. We need $n$ cubes to form a circle of radius $R$. The area of the filled circle of radius $R$ is $\\pi R^2$, and the area of the circle of radius $r$ is $\\pi r^2$. Hence the number of cubes approximately equal to the area difference is $\\pi (R^2 - r^2)$.\n",
       "Since the number of cubes must be an integer, we can write $N \\approx \\pi (R^2 - r^2)$.\n",
       "\n",
       "We can consider the cross-section as a ring. The number of cubes around the circular loop is $m$. The number of cubes in the circular cross-section can be estimated as the area of the ring, which is $\\pi(R^2 - r^2)$.\n",
       "Let $C$ be the circumference of the central circle, which is $C = 2\\pi r$.\n",
       "The number of cubes in the cross-section is approximately the area of the toroidal surface, which is given by $A = (2\\pi r)(2\\pi R) = 4\\pi^2 rR$.\n",
       "To minimize the number of cubes, one must consider the smallest side length.\n",
       "However, we need to consider the fact that the torus can be viewed as a surface of revolution.\n",
       "We can visualize the torus as a collection of annuli.\n",
       "The torus is approximately $\\pi R^2 - \\pi r^2$ squared. This can be interpreted as the area of the cross section. The \"thickness\" of the donut is the side length of the small cubes, which we assume to be 1. So the number of cubes is the product of the area of the cross section and the area around it.\n",
       "\n",
       "The area of the cross-sectional ring is $\\pi(R^2 - r^2)$. The circumference of the hole is $2\\pi r$.\n",
       "So the total number of cubes is approximately $2\\pi r \\times \\pi (R^2 - r^2) = 2\\pi^2 r(R^2 - r^2)$.\n",
       "However, for the cubes to form a solid torus, we can express the volume as an integral, where the cross-sectional area varies.\n",
       "The number of cubes can be approximated as the surface area of the torus multiplied by the side length of the cube.\n",
       "Surface Area of Torus: $A = (2\\pi r)(2\\pi R) = 4\\pi^2 rR$.\n",
       "Let $s$ be the side length of the cube, which is minimized when $s$ is smallest.\n",
       "So the number of cubes is $4\\pi^2 rR$.\n",
       "Since we have infinitesimally small cubes, $s \\rightarrow 0$.\n",
       "The number of cubes is approximately $4\\pi^2 rR$.\n",
       "\n",
       "If the torus were assembled from unit cubes, then the number of cubes would be the volume of a cylinder with radii *r* and *R*, with length 1. The volume is $\\pi R^2 - \\pi r^2$, but this doesn't account for the fact that we have a torus.  Consider the torus as a surface of revolution. The area is $4 \\pi^2 r R$.\n",
       "\n",
       "Final Answer: The final answer is $\\boxed{4\\pi^2rR}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response.choices[0].message.content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthcare\n"
     ]
    }
   ],
   "source": [
    "# First create the messages:\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Choose a business area that might be worth exploring for an Agentic AI opportunity. Only reply with it\"}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = ollama.chat.completions.create(model=\"gemma3:12b\", messages=messages)\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.choices[0].message.content\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message\n",
    "\n",
    "print(business_idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a pain point in Customer Service, framed for potential Agentic solution consideration:\n",
      "\n",
      "**Problem:** In a large e-commerce company like \"Bloom & Grow\" (selling plants and gardening supplies), customer service agents frequently spend a significant portion of their time (around 20-30%) handling repetitive \"how-to\" inquiries related to basic plant care – things like \"How much water does a succulent need?\", \"What kind of soil is best for roses?\", or \"Why are my leaves yellowing?\". This ties up experienced agents who could be addressing more complex issues and frustrates customers who often expect immediate, standardized answers.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": f\"Present a pain-point in {\"Customer Service\"}, something challenging that might be chosen for an Agentic solution. Describe the problem in one sentence/paragraph with context.\"}]\n",
    "\n",
    "response = ollama.chat.completions.create(model=\"gemma3:12b\", messages=messages)\n",
    "\n",
    "problem = response.choices[0].message.content\n",
    "\n",
    "print(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Agentic AI Solution: \"BloomAssist\" for Bloom & Grow Customer Service\n",
      "\n",
      "Here’s an Agentic AI solution designed to address the \"how-to\" inquiry problem at Bloom & Grow, dubbed \"BloomAssist.\" It's built around the idea of an AI agent that intelligently handles these routine questions, freeing up human agents for complex issues and enhancing customer experience.\n",
      "\n",
      "**1. Core Concept: Tiered AI Agentic Workflow**\n",
      "\n",
      "BloomAssist isn't a single bot, but a system of interconnected agents working in tiers with human oversight. This is key to handling potential edge cases and maintaining accuracy.\n",
      "\n",
      "**2. Agent Breakdown & Responsibilities:**\n",
      "\n",
      "* **Tier 1: \"BloomGPT\" - Initial Response & Knowledge Retrieval (Fastest, Simplest)**\n",
      "    * **AI Model:** Fine-tuned Large Language Model (LLM) like GPT-4 or similar, specifically trained on Bloom & Grow's product data, plant care guides, FAQ documents, and commonly asked questions.\n",
      "    * **Role:**  Handles the initial interaction.\n",
      "    * **Functionality:**\n",
      "        * **Intent Recognition:**  Identifies the customer's underlying question (e.g., \"How much water...\").\n",
      "        * **Knowledge Base Search:** Queries a structured knowledge base of plant care information, curated by a team of horticultural experts at Bloom & Grow.  This ensures accuracy and prevents hallucination.\n",
      "        * **Standard Reply Generation:** Generates a concise, standardized answer based on the knowledge base.  Answers formatted with clear instructions and helpful links (e.g., to blog posts, product pages).\n",
      "        * **Example Interaction:**\n",
      "            * **Customer:** \"How much water does a succulent need?\"\n",
      "            * **BloomGPT:** \"Succulents are drought-tolerant plants and generally need infrequent watering. We recommend watering thoroughly when the soil is completely dry, usually every 2-4 weeks depending on the season and environment.  For more details, check out our succulent care guide: [Link to guide]\"\n",
      "* **Tier 2: \"BloomContext\" - Contextual Understanding & Advanced Recommendations (Slightly Slower, More Personalized)**\n",
      "    * **AI Model:**  Combination of NLP models designed to understand customer context (previous interactions, purchased plants, expressed expertise).  May incorporate a product recommendation engine.\n",
      "    * **Role:**  Refines BloomGPT's answers and provides more personalized assistance when needed.\n",
      "    * **Functionality:**\n",
      "        * **Contextual Analysis:**  Looks at purchase history (e.g., \"customer bought a peace lily - potential yellowing issue might be related to humidity\").\n",
      "        * **Proactive Information:**  Offers related information  – “Since you purchased a rose bush, are you aware of our fertilization guide?”\n",
      "        * **Troubleshooting Basics:**  Can handle slightly more complex \"Why are my leaves yellowing?\" scenarios, asking clarifying questions (“Are the leaves brown/dry or yellow/soft?  What’s the lighting like?”) to narrow down the issue.\n",
      "* **Tier 3: \"BloomEscalator\" - Human Agent Hand-Off (Slowest, Most Complex)**\n",
      "    * **AI Model:**  Rules-based system & Sentiment Analysis.\n",
      "    * **Role:**  Determines when a human agent is necessary.\n",
      "    * **Functionality:**\n",
      "        * **Confidence Scoring:** BloomGPT & BloomContext assign a confidence score to their responses.  Low confidence triggers escalation.\n",
      "        * **Keyword Triggers:** Certain keywords (\"urgent,\" \"dying,\" \"pest,\" \"diseased,\" coupled with negative sentiment detected via sentiment analysis) automatically escalate.\n",
      "        * **Request Escalation:** Customer can explicitly request a human agent.\n",
      "        * **Agent Briefing:**  Transfers the entire conversation history and context to the assigned human agent.\n",
      "\n",
      "**3. Architecture & Technology Stack:**\n",
      "\n",
      "* **LLM:** GPT-4 (or equivalent), fine-tuned on Bloom & Grow data.\n",
      "* **Knowledge Base:**  Structured database (e.g., PostgreSQL with JSONB support) populated with plant care information.\n",
      "* **NLP Pipeline:**  SpaCy, NLTK (for tokenization, POS tagging, named entity recognition).\n",
      "* **Conversation Engine:**  Dialogflow, Rasa (for managing conversations and agent orchestration).\n",
      "* **API Integrations:**\n",
      "    * **CRM (e.g., Salesforce):** To access customer purchase history and previous interactions.\n",
      "    * **E-commerce Platform:** To pull product information and linking to relevant product pages.\n",
      "* **Monitoring & Analytics:**  Dashboards to track agent performance, customer satisfaction, and identify areas for improvement.\n",
      "\n",
      "\n",
      "**4. Workflow Example:**\n",
      "\n",
      "1. **Customer initiates chat:** \"My succulent's leaves are shriveled.\"\n",
      "2. **BloomGPT:** Identifies intent (\"watering problem,\" \"succulent\").  Retrieves information about succulent watering needs from the knowledge base.  Responds: \"Succulents need infrequent watering.  Allow the soil to dry completely between waterings. Here’s a guide: [Link].\"\n",
      "3. **Customer:** \"I do that, but they're still shriveling!\"\n",
      "4. **BloomContext:**  Recognizes customer persistence and lack of resolution. Checks customer's purchase history – they bought several succulents simultaneously.  Asks: “Could you describe the type of soil you're using?  Are they getting enough light?”\n",
      "5. **Customer:** \"I just used regular potting soil, and they're on a windowsill with decent light.\"\n",
      "6. **BloomContext:**  Recognizes regular potting soil may not be ideal for succulents (poor drainage). Suggests amending the soil with perlite/sand.  Also recommends checking for root rot.\n",
      "7. **Customer:** “I’m worried about root rot.”\n",
      "8. **BloomEscalator:**  Detects customer concern (\"worried\"). Triggers escalation to a human agent.  Agent receives full conversation history and BloomContext's assessment of potential root rot.\n",
      "\n",
      "**5. Benefits:**\n",
      "\n",
      "* **Reduced Agent Load:** Frees up experienced agents to handle more complex issues.\n",
      "* **Improved Customer Experience:** Provides faster, consistent answers to common questions.\n",
      "* **Increased Efficiency:** Automates a significant portion of routine customer service inquiries.\n",
      "* **Knowledge Consistency:** Ensures all customers receive the same accurate information.\n",
      "* **Data-Driven Improvement:**  Provides data to improve knowledge base and agent training.\n",
      "\n",
      "**6. Considerations & Future Enhancements:**\n",
      "\n",
      "* **Initial Training Data:** Requires a significant investment in creating and maintaining the knowledge base.\n",
      "* **Edge Case Handling:** BloomEscalator is crucial for dealing with scenarios the agents can't handle.\n",
      "* **Language Support:**  Needs to be adapted for different languages.\n",
      "* **Personalized Recommendations:** Future iterations could offer truly personalized plant care recommendations based on customer's environment, lifestyle, and skill level.\n",
      "* **Image Recognition:**  Integrate image recognition to diagnose plant problems based on customer-submitted photos.\n",
      "\n",
      "\n",
      "\n",
      "By implementing BloomAssist, Bloom & Grow can transform its customer service operation, providing faster, more efficient support while empowering its agents to focus on more challenging and valuable tasks.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": f\"Present an Agentic AI solution for this problem: {problem}\"}]\n",
    "\n",
    "response = ollama.chat.completions.create(model=\"gemma3:12b\", messages=messages)\n",
    "\n",
    "solution = response.choices[0].message.content\n",
    "\n",
    "print(solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Agentic AI Solution: \"BloomAssist\" for Bloom & Grow Customer Service\n",
       "\n",
       "Here’s an Agentic AI solution designed to address the \"how-to\" inquiry problem at Bloom & Grow, dubbed \"BloomAssist.\" It's built around the idea of an AI agent that intelligently handles these routine questions, freeing up human agents for complex issues and enhancing customer experience.\n",
       "\n",
       "**1. Core Concept: Tiered AI Agentic Workflow**\n",
       "\n",
       "BloomAssist isn't a single bot, but a system of interconnected agents working in tiers with human oversight. This is key to handling potential edge cases and maintaining accuracy.\n",
       "\n",
       "**2. Agent Breakdown & Responsibilities:**\n",
       "\n",
       "* **Tier 1: \"BloomGPT\" - Initial Response & Knowledge Retrieval (Fastest, Simplest)**\n",
       "    * **AI Model:** Fine-tuned Large Language Model (LLM) like GPT-4 or similar, specifically trained on Bloom & Grow's product data, plant care guides, FAQ documents, and commonly asked questions.\n",
       "    * **Role:**  Handles the initial interaction.\n",
       "    * **Functionality:**\n",
       "        * **Intent Recognition:**  Identifies the customer's underlying question (e.g., \"How much water...\").\n",
       "        * **Knowledge Base Search:** Queries a structured knowledge base of plant care information, curated by a team of horticultural experts at Bloom & Grow.  This ensures accuracy and prevents hallucination.\n",
       "        * **Standard Reply Generation:** Generates a concise, standardized answer based on the knowledge base.  Answers formatted with clear instructions and helpful links (e.g., to blog posts, product pages).\n",
       "        * **Example Interaction:**\n",
       "            * **Customer:** \"How much water does a succulent need?\"\n",
       "            * **BloomGPT:** \"Succulents are drought-tolerant plants and generally need infrequent watering. We recommend watering thoroughly when the soil is completely dry, usually every 2-4 weeks depending on the season and environment.  For more details, check out our succulent care guide: [Link to guide]\"\n",
       "* **Tier 2: \"BloomContext\" - Contextual Understanding & Advanced Recommendations (Slightly Slower, More Personalized)**\n",
       "    * **AI Model:**  Combination of NLP models designed to understand customer context (previous interactions, purchased plants, expressed expertise).  May incorporate a product recommendation engine.\n",
       "    * **Role:**  Refines BloomGPT's answers and provides more personalized assistance when needed.\n",
       "    * **Functionality:**\n",
       "        * **Contextual Analysis:**  Looks at purchase history (e.g., \"customer bought a peace lily - potential yellowing issue might be related to humidity\").\n",
       "        * **Proactive Information:**  Offers related information  – “Since you purchased a rose bush, are you aware of our fertilization guide?”\n",
       "        * **Troubleshooting Basics:**  Can handle slightly more complex \"Why are my leaves yellowing?\" scenarios, asking clarifying questions (“Are the leaves brown/dry or yellow/soft?  What’s the lighting like?”) to narrow down the issue.\n",
       "* **Tier 3: \"BloomEscalator\" - Human Agent Hand-Off (Slowest, Most Complex)**\n",
       "    * **AI Model:**  Rules-based system & Sentiment Analysis.\n",
       "    * **Role:**  Determines when a human agent is necessary.\n",
       "    * **Functionality:**\n",
       "        * **Confidence Scoring:** BloomGPT & BloomContext assign a confidence score to their responses.  Low confidence triggers escalation.\n",
       "        * **Keyword Triggers:** Certain keywords (\"urgent,\" \"dying,\" \"pest,\" \"diseased,\" coupled with negative sentiment detected via sentiment analysis) automatically escalate.\n",
       "        * **Request Escalation:** Customer can explicitly request a human agent.\n",
       "        * **Agent Briefing:**  Transfers the entire conversation history and context to the assigned human agent.\n",
       "\n",
       "**3. Architecture & Technology Stack:**\n",
       "\n",
       "* **LLM:** GPT-4 (or equivalent), fine-tuned on Bloom & Grow data.\n",
       "* **Knowledge Base:**  Structured database (e.g., PostgreSQL with JSONB support) populated with plant care information.\n",
       "* **NLP Pipeline:**  SpaCy, NLTK (for tokenization, POS tagging, named entity recognition).\n",
       "* **Conversation Engine:**  Dialogflow, Rasa (for managing conversations and agent orchestration).\n",
       "* **API Integrations:**\n",
       "    * **CRM (e.g., Salesforce):** To access customer purchase history and previous interactions.\n",
       "    * **E-commerce Platform:** To pull product information and linking to relevant product pages.\n",
       "* **Monitoring & Analytics:**  Dashboards to track agent performance, customer satisfaction, and identify areas for improvement.\n",
       "\n",
       "\n",
       "**4. Workflow Example:**\n",
       "\n",
       "1. **Customer initiates chat:** \"My succulent's leaves are shriveled.\"\n",
       "2. **BloomGPT:** Identifies intent (\"watering problem,\" \"succulent\").  Retrieves information about succulent watering needs from the knowledge base.  Responds: \"Succulents need infrequent watering.  Allow the soil to dry completely between waterings. Here’s a guide: [Link].\"\n",
       "3. **Customer:** \"I do that, but they're still shriveling!\"\n",
       "4. **BloomContext:**  Recognizes customer persistence and lack of resolution. Checks customer's purchase history – they bought several succulents simultaneously.  Asks: “Could you describe the type of soil you're using?  Are they getting enough light?”\n",
       "5. **Customer:** \"I just used regular potting soil, and they're on a windowsill with decent light.\"\n",
       "6. **BloomContext:**  Recognizes regular potting soil may not be ideal for succulents (poor drainage). Suggests amending the soil with perlite/sand.  Also recommends checking for root rot.\n",
       "7. **Customer:** “I’m worried about root rot.”\n",
       "8. **BloomEscalator:**  Detects customer concern (\"worried\"). Triggers escalation to a human agent.  Agent receives full conversation history and BloomContext's assessment of potential root rot.\n",
       "\n",
       "**5. Benefits:**\n",
       "\n",
       "* **Reduced Agent Load:** Frees up experienced agents to handle more complex issues.\n",
       "* **Improved Customer Experience:** Provides faster, consistent answers to common questions.\n",
       "* **Increased Efficiency:** Automates a significant portion of routine customer service inquiries.\n",
       "* **Knowledge Consistency:** Ensures all customers receive the same accurate information.\n",
       "* **Data-Driven Improvement:**  Provides data to improve knowledge base and agent training.\n",
       "\n",
       "**6. Considerations & Future Enhancements:**\n",
       "\n",
       "* **Initial Training Data:** Requires a significant investment in creating and maintaining the knowledge base.\n",
       "* **Edge Case Handling:** BloomEscalator is crucial for dealing with scenarios the agents can't handle.\n",
       "* **Language Support:**  Needs to be adapted for different languages.\n",
       "* **Personalized Recommendations:** Future iterations could offer truly personalized plant care recommendations based on customer's environment, lifestyle, and skill level.\n",
       "* **Image Recognition:**  Integrate image recognition to diagnose plant problems based on customer-submitted photos.\n",
       "\n",
       "\n",
       "\n",
       "By implementing BloomAssist, Bloom & Grow can transform its customer service operation, providing faster, more efficient support while empowering its agents to focus on more challenging and valuable tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(solution))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
